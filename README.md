# ARDC_GRP_2 - iLab 2 project 

## Project Overview
In the era of real-time information, social media, especially Twitter, has become invaluable during natural disasters. To tackle the overwhelming volume of data generated, we've developed a machine learning model that detects and analyzes emotions in disaster-related tweets. Our chatbot, HurricaneBot, offers tailored recommendations based on these emotions, providing guidance during crises.

Our primary goal is to streamline disaster response by identifying emotions like anxiety and fear in tweets. HurricaneBot steps in to provide vital information, including evacuation guidance, safety tips, and emergency contacts, ensuring more efficient and emotionally intelligent support.

In our future scope, we plan to integrate geolocation data from tweets, allowing precise location-based aid delivery. This innovation will empower agencies and organizations to provide timely assistance during disasters, ultimately improving disaster response effectiveness.

## Tools and installing support 

## Hybrid annotation 
In the project's early stages, a critical challenge was acquiring tweet data annotated with emotional content. However, this task proved to be highly resource and time-intensive, and publicly available annotated datasets were scarce. To address this challenge, we adopted a hybrid annotation approach that combined the capabilities of Large Language Models (LLMs) and the NRC Lexicon for initial annotation, followed by a comprehensive verification process conducted by a human annotator.

### NRC Lexicon for Annotating 'fear,' 'sadness,' and 'anger'

The methodology for annotating text data with specific emotions, notably fear, sadness, and anger, was meticulously structured to gain deeper insights into the emotional content embedded within textual information. In this section, we delineate the systematic approach employed to analyze and annotate text data, focusing on emotions such as fear, anxiety, sadness, anger, helplessness, relief, frustration, confusion, empathy, and hope.

To ensure precision in sentiment analysis, we commenced by defining a comprehensive list of emotions referred to as "emotions_to_check." This list included specific emotions of interest, thereby providing clear guidance for sentiment analysis. The data underwent a systematic loop, addressing missing values, utilizing the NRCLex library for emotion analysis, and evaluating emotion presence based on emotional scores from the NRC Emotion Lexicon. Each text's emotional presence or absence was captured, resulting in a binary representation of emotion presence. The results were collected systematically for all texts and added as columns in the dataset. These additional columns indicated the presence or absence of specific emotions, contributing to a structured dataset for further analysis. A crucial step involved manual verification to ensure that the automated emotion assignments matched the emotions presented in the output, enhancing the reliability and accuracy of the annotated dataset for subsequent project phases. This approach provided a robust foundation for emotional analysis within the project.

## Classification Model 

## Disaster chatBot
### interface Sample

![plot](https://github.com/BharaniSurya/ARDC_GRP_2/blob/main/MicrosoftTeams-image%20(3).png)

### work flow
![plot](https://github.com/BharaniSurya/ARDC_GRP_2/blob/main/MicrosoftTeams-image%20(4).png)
#### Fine-Tuning and Saving the Model: 
We began by fine-tuning the model and saving both the model and tokenizer for future use. This step was crucial for deploying the chatbot in real-world scenarios and ensuring its long-term viability.

#### Integration with Lang Chain:
Connecting the fine-tuned model to Lang Chain expanded its capabilities for use in production environments. We established a pipeline for generating responses, enabling the chatbot to interact with users effectively and showcasing its potential to offer valuable assistance during disasters.

#### Template Framework Development: 
To prepare the chatbot for action, we developed a series of templates that guided the model in generating compassionate, supportive, and empathetic responses. These templates provided a structured framework for crafting responses that were non-judgmental and genuinely helpful.

#### API Development with Flask: 
The final piece of the puzzle involved creating the chatbot's API using Flask. We developed an API endpoint capable of accepting user queries and delivering responses generated by the fine-tuned model. This API ensured the chatbot's seamless integration into various platforms and services, enhancing its accessibility and utility.

#### Streamlit Frontend: 
We used Streamlit to design and develop the chatbot's frontend, providing an intuitive and user-friendly interface for users to interact with the chatbot.
