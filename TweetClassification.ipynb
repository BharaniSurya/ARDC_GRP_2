{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e737d5-2e9d-47f6-a4b2-9f043d217fce",
   "metadata": {},
   "source": [
    "# Disaster classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673f391-c259-4fa3-b0f1-92bed627dbc8",
   "metadata": {},
   "source": [
    "## 1. Importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd09447-caeb-4f05-a74a-fc709e0a9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a7da2-1289-4c7c-9189-4a57f8d767fe",
   "metadata": {},
   "source": [
    "## 2. Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c544a0f-a6cc-4b5e-bdd5-c918fcda8bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Morgantown, WV</td>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword        location  \\\n",
       "0   0  ablaze             NaN   \n",
       "1   1  ablaze             NaN   \n",
       "2   2  ablaze   New York City   \n",
       "3   3  ablaze  Morgantown, WV   \n",
       "4   4  ablaze             NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1  \n",
       "1  Telangana: Section 144 has been imposed in Bha...       1  \n",
       "2  Arsonist sets cars ablaze at dealership https:...       1  \n",
       "3  Arsonist sets cars ablaze at dealership https:...       1  \n",
       "4  \"Lord Jesus, your love brings freedom and pard...       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/savinaysingh/Downloads/tweets 2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ae3594-9f3a-4662-9a33-35d2c4cce4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1\n",
       "1  Telangana: Section 144 has been imposed in Bha...       1\n",
       "2  Arsonist sets cars ablaze at dealership https:...       1\n",
       "3  Arsonist sets cars ablaze at dealership https:...       1\n",
       "4  \"Lord Jesus, your love brings freedom and pard...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading required features\n",
    "data = data[['text','target']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed5f943-81ae-4194-a424-f9f2b1bcab48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8310cc-3152-4dc5-938d-2a69daa33df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    communal violence in bhainsa, telangana. \"ston...\n",
       "1    telangana: section 144 has been imposed in bha...\n",
       "2    arsonist sets cars ablaze at dealership https:...\n",
       "3    arsonist sets cars ablaze at dealership https:...\n",
       "4    \"lord jesus, your love brings freedom and pard...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = [entry.lower() for entry in data['text']]\n",
    "data['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e1694fb-253f-403c-9a9b-23652204a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url not req while finding if text is disaster or not\n",
    "def remove_urls(text):\n",
    "    pattern = re.compile(r'http\\S+|www\\S+')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "# spl chars not req while finding if text is disaster or not\n",
    "def remove_special_characters(text):\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    pattern = re.compile(r'#\\w+')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return emoji.demojize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e261aae2-2a71-4787-960c-1857522c7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = remove_urls(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_hashtags(text)\n",
    "    text = remove_emojis(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e1c426-dbe3-4d77-9dc2-7cd967945121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7102ad52-f120-44cc-9712-677758b682a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    9254\n",
      "1    2114\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].map(len) > 0]\n",
    "class_counts = data['target'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e3e9e95-41ce-4c7e-8573-9e29a7c8645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./iLab-env/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./iLab-env/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./iLab-env/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./iLab-env/lib/python3.8/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./iLab-env/lib/python3.8/site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "638d5629-0236-49c3-9042-892ee6941b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/savinaysingh/Documents/SavinayUTS/iLab/Code/iLab-env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43932650-af85-4021-ab63-87f1c3cb221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    data['text'],\n",
    "    data['target'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e828dd3-85ed-4d21-8f96-5458256b64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize the input texts\n",
    "train_encodings = tokenizer(train_data.tolist(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_data.tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91f16f1-d973-44e4-b71f-d54210434103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[index])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e7d89fd-7e70-4476-9ac6-139d8cfc05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets\n",
    "train_dataset = TextDataset(train_encodings, train_labels.tolist())\n",
    "val_dataset = TextDataset(val_encodings, val_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f578cb-30f3-4b01-a690-5f006f7ea418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/savinaysingh/Documents/SavinayUTS/iLab/Code/iLab-env/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the model configuration\n",
    "model_config = RobertaConfig.from_pretrained('roberta-base', num_labels=2)\n",
    "model_config.hidden_dropout_prob = 0.2  # Dropout probability'\n",
    "\n",
    "# Create a data loader for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', config=model_config)\n",
    "\n",
    "# Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2145b-fbc7-433b-90e5-1e20a35f0688",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.3088 | Validation Loss: 0.2704\n",
      "Train Accuracy: 86.89% | Validation Accuracy: 88.87%\n",
      "Train F1-score: 0.6019 | Validation F1-score: 0.7323\n",
      "Epoch: 2\n",
      "Train Loss: 0.2242 | Validation Loss: 0.2128\n",
      "Train Accuracy: 90.84% | Validation Accuracy: 91.16%\n",
      "Train F1-score: 0.7422 | Validation F1-score: 0.7426\n",
      "Epoch: 3\n",
      "Train Loss: 0.1844 | Validation Loss: 0.3383\n",
      "Train Accuracy: 93.07% | Validation Accuracy: 87.95%\n",
      "Train F1-score: 0.8076 | Validation F1-score: 0.7227\n",
      "Epoch: 4\n",
      "Train Loss: 0.1529 | Validation Loss: 0.2493\n",
      "Train Accuracy: 93.93% | Validation Accuracy: 89.89%\n",
      "Train F1-score: 0.8345 | Validation F1-score: 0.7450\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "num_epochs = 20  # Define the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs.logits, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted_labels == labels).sum().item()\n",
    "\n",
    "        predictions.extend(predicted_labels.tolist())\n",
    "        true_labels.extend(labels.tolist())\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = 100.0 * train_correct / train_total\n",
    "    train_f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_predictions = []\n",
    "    val_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted_labels = torch.max(outputs.logits, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted_labels == labels).sum().item()\n",
    "\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_true_labels.extend(labels.tolist())\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100.0 * val_correct / val_total\n",
    "    val_f1 = f1_score(val_true_labels, val_predictions)\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.2f}% | Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    print(f\"Train F1-score: {train_f1:.4f} | Validation F1-score: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d5254-96b2-4004-9d2f-1d0938933e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_data = pd.read_csv('/kaggle/input/disaster-tweets/tweets.csv')\n",
    "test_data['text'] = test_data['text'].apply(preprocess_text)\n",
    "test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True)\n",
    "test_dataset = TextDataset(test_encodings, test_data['target'].tolist())\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "        test_predictions.extend(predictions)\n",
    "\n",
    "test_data['predicted_target'] = test_predictions\n",
    "test_data[['text', 'predicted_target']].to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc9085-a4fe-428f-82db-110c607db0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "test_true_labels = test_data['target'].tolist()\n",
    "test_predicted_labels = test_data['predicted_target'].tolist()\n",
    "\n",
    "# Calculate F1-score and accuracy\n",
    "test_f1 = f1_score(test_true_labels, test_predicted_labels)\n",
    "test_accuracy = accuracy_score(test_true_labels, test_predicted_labels) * 100\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Test F1-score: {test_f1:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(test_true_labels, test_predicted_labels)\n",
    "classes = ['Non-Disaster', 'Disaster']\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', cbar=False,\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c503f-eee9-4d50-af61-83d6eb436193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of input texts\n",
    "input_texts = [\n",
    "    \"Communal violence in Bhainsa, Telangana. Stones were pelted on Muslims' houses and some houses and vehicles were set ablaze…\",\n",
    "    \"Lord Jesus, your love brings freedom and pardon. Fill me with your Holy Spirit and set my heart ablaze with your l… https://t.co/VlTznnPNi8\",\n",
    "    \"Juwan Johnson/Oregon is one big dude. Looks like a tight end stuck in the receiver group by accident.\",\n",
    "    \"Telangana: Section 144 has been imposed in Bhainsa from January 13 to 15, after clash erupted between two groups on January 12. \",\n",
    "    \"Kumera yellow Aftershock #PH19FOSSIL featured in bankbtn Good Living magazine Photography Stylist shino… https://t.co/V9LJ65ttzR\"\n",
    "]\n",
    "\n",
    "expected = [\n",
    "    \"Disaster\", \"Not Disaster\", \"Not Disaster\", \"Disaster\", \"Not Disaster\"\n",
    "]\n",
    "\n",
    "# Preprocess the input texts\n",
    "preprocessed_texts = [preprocess_text(text) for text in input_texts]\n",
    "input_encodings = tokenizer(preprocessed_texts, truncation=True, padding=True)\n",
    "input_dataset = TextDataset(input_encodings, None)\n",
    "input_loader = DataLoader(input_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(input_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1).tolist()\n",
    "        prediction = 'Disaster' if predictions[0] == 1 else 'Not Disaster'\n",
    "        print(f\"Input: {input_texts[i]}\")\n",
    "        print(f\"Target: {expected[i]}\")\n",
    "        print(f\"Prediction: {prediction}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c876ee-ee74-4196-9730-b4a6dee821e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iLab-env",
   "language": "python",
   "name": "ilab-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
